{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import utilities as u\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "from gensim.models import KeyedVectors\n",
    "EMBEDDING_FILE = '../GoogleNews-vectors-negative300.bin.gz'\n",
    "model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jac812i/virtualenvs/quoravenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read training and test data from .csv files\n",
    "train_df = pd.read_csv(\"../train.csv\")\n",
    "test_df = pd.read_csv(\"../test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 3 rows of train data\n",
    "train_df.head(3)\n",
    "# assert the shape of train dataframe\n",
    "assert train_df.shape == (404290, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display top 3 rows of test data and assert test data shape\n",
    "test_df.head(3)\n",
    "assert test_df.shape == (3563475, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id                                          question1  \\\n",
       "0       0  How does the Surface Pro himself 4 compare wit...   \n",
       "1       1  Should I have a hair transplant at age 24? How...   \n",
       "2       2  What but is the best way to send money from Ch...   \n",
       "3       3                        Which food not emulsifiers?   \n",
       "4       4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Feature and Target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns ['id', 'qid1', 'qid2', 'question1', 'question2']\n",
      "Target Columns is_duplicate\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(train_df.columns[:-1])\n",
    "target_col = train_df.columns[-1]\n",
    "print (\"Feature Columns {}\".format(feature_cols))\n",
    "print (\"Target Columns {}\".format(target_col))\n",
    "X_all = train_df[feature_cols]\n",
    "y_all = pd.DataFrame(data=train_df[target_col], columns=[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 255027, 1: 149263})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if the data is balanced or not\n",
    "collections.Counter(y_all['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0\n",
       "5             1\n",
       "6             0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the 5 rows of train output\n",
    "y_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "\n",
       "                                           question2  \n",
       "0  What is the step by step guide to invest in sh...  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.head(3)\n",
    "assert X_all.shape == (train_df.shape[0],train_df.shape[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data in training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check whether data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data set: 404290 samples\n",
      "Training set: 283003 samples\n",
      "Valid set: 121287 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data into 30% and have a constant random state so that the results are consistent\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, test_size=0.30, random_state=42)\n",
    "print (\"Total data set: {} samples\".format(X_all.shape[0]))\n",
    "print (\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print (\"Valid set: {} samples\".format(X_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert (X_train.shape[0] + X_valid.shape[0]) == X_all.shape[0]\n",
    "assert (y_train.shape[0] + y_valid.shape[0]) == y_all.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check whether data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 178677, 1: 104326})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO check how many question pairs in training set are duplicate or not\n",
    "collections.Counter(y_train['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 76350, 1: 44937})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(y_valid['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567       How do I improve logical programming skills?   \n",
       "73186              How close we are to see 3rd world war?   \n",
       "\n",
       "                                                question2  \n",
       "8067                   How do I play Pokémon GO in China?  \n",
       "368101  What are some good side dishes for buffalo chi...  \n",
       "70497       What is the best server setup for buddypress?  \n",
       "226567  How can I improve my logical skills for progra...  \n",
       "73186                       How close is a World War III?  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate\n",
       "8067               0\n",
       "368101             0\n",
       "70497              0\n",
       "226567             1\n",
       "73186              1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(words_list,df,column_name):\n",
    "    for sentence in df[column_name]:\n",
    "        for word in sentence:\n",
    "            words_list.append(word)\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_baseline_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'do', 'i', 'play', 'pokémon', 'go', 'in', 'korea?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_baseline_text('How do I play Pokémon GO in Korea?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all_1 = pd.DataFrame()\n",
    "test_df_1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all_1['question1'] = X_all['question1'].apply(lambda x:preprocess_baseline_text(x))\n",
    "X_all_1['question2'] = X_all['question2'].apply(lambda x:preprocess_baseline_text(x))\n",
    "test_df_1['question1'] = test_df['question1'].apply(lambda x:preprocess_baseline_text(x))\n",
    "test_df_1['question2'] = test_df['question2'].apply(lambda x:preprocess_baseline_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[what, is, the, story, of, kohinoor, (koh-i-no...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[why, am, i, mentally, very, lonely?, how, can...</td>\n",
       "      <td>[find, the, remainder, when, [math]23^{24}[/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water?]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1  [what, is, the, story, of, kohinoor, (koh-i-no...   \n",
       "2  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3  [why, am, i, mentally, very, lonely?, how, can...   \n",
       "4  [which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                           question2  \n",
       "0  [what, is, the, step, by, step, guide, to, inv...  \n",
       "1  [what, would, happen, if, the, indian, governm...  \n",
       "2  [how, can, internet, speed, be, increased, by,...  \n",
       "3  [find, the, remainder, when, [math]23^{24}[/ma...  \n",
       "4    [which, fish, would, survive, in, salt, water?]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[how, does, the, surface, pro, himself, 4, com...</td>\n",
       "      <td>[why, did, microsoft, choose, core, m3, and, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[should, i, have, a, hair, transplant, at, age...</td>\n",
       "      <td>[how, much, cost, does, hair, transplant, requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[what, but, is, the, best, way, to, send, mone...</td>\n",
       "      <td>[what, you, send, money, to, china?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[which, food, not, emulsifiers?]</td>\n",
       "      <td>[what, foods, fibre?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[how, \"aberystwyth\", start, reading?]</td>\n",
       "      <td>[how, their, can, i, start, reading?]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  [how, does, the, surface, pro, himself, 4, com...   \n",
       "1  [should, i, have, a, hair, transplant, at, age...   \n",
       "2  [what, but, is, the, best, way, to, send, mone...   \n",
       "3                   [which, food, not, emulsifiers?]   \n",
       "4              [how, \"aberystwyth\", start, reading?]   \n",
       "\n",
       "                                           question2  \n",
       "0  [why, did, microsoft, choose, core, m3, and, n...  \n",
       "1  [how, much, cost, does, hair, transplant, requ...  \n",
       "2               [what, you, send, money, to, china?]  \n",
       "3                              [what, foods, fibre?]  \n",
       "4              [how, their, can, i, start, reading?]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of words in X_all question 1 4423826\n",
      "Lenght of words after adding X_all question 2 8944593\n",
      "Lenght of words after adding test_df question 1 48146246\n",
      "Lenght of words after adding test_df question 2 87470531\n"
     ]
    }
   ],
   "source": [
    "words_list = create_vocabulary([],X_all_1,'question1')\n",
    "print (\"Lenght of words in X_all question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_all_1,'question2')\n",
    "print (\"Lenght of words after adding X_all question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,test_df_1,'question1')\n",
    "print (\"Lenght of words after adding test_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,test_df_1,'question2')\n",
    "print (\"Lenght of words after adding test_df question 2 {}\".format(len(words_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327522\n",
      "['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in']\n",
      "6614\n",
      "3386\n"
     ]
    }
   ],
   "source": [
    "print (len(set(words_list)))\n",
    "print (words_list[0:10])\n",
    "words_freq = collections.Counter(words_list)\n",
    "words_freq.most_common(10)\n",
    "words_freq_10000 = words_freq.most_common(10000)\n",
    "\n",
    "\n",
    "word_in_word2vec = []\n",
    "word_notin_word2vec = []\n",
    "\n",
    "for word in words_freq.most_common(10000):\n",
    "    if word[0] in model.vocab:\n",
    "        word_in_word2vec.append(word[0])\n",
    "    else:\n",
    "        word_notin_word2vec.append(word[0])\n",
    "        \n",
    "print (len(word_in_word2vec))\n",
    "print (len(word_notin_word2vec))\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3398855), ('what', 2980203), ('is', 2573361), ('how', 2090590), ('i', 2060339), ('a', 2028806), ('in', 1944305), ('to', 1898636), ('of', 1467452), ('do', 1374660), ('are', 1294421), ('and', 1223643), ('can', 1072247), ('for', 1012448), ('why', 707330), ('you', 699351), ('my', 666512), ('best', 632025), ('it', 581168), ('on', 547035), ('does', 521099), ('which', 466737), ('or', 461708), ('if', 408308), ('get', 386807), ('with', 384513), ('be', 375348), ('should', 372922), ('an', 362490), ('have', 361547), ('that', 357477), ('some', 351606), ('from', 325810), ('your', 272379), ('when', 258746), ('will', 250735), ('who', 247316), ('at', 246414), ('good', 233478), ('like', 223882), ('there', 214642), ('people', 212807), ('as', 210562), ('would', 208053), ('between', 196776), ('where', 190411), ('one', 181467), ('about', 178274), ('most', 171376), ('way', 167888), ('make', 167313), ('any', 165852), ('not', 161751), ('we', 159834), ('by', 155638), ('india?', 155451), ('after', 148930), ('did', 148650), ('was', 148272), ('am', 138205), ('difference', 136870), ('they', 134790), ('has', 126469), ('much', 126192), (\"what's\", 125564), ('so', 124523), ('learn', 121898), ('use', 120767), ('know', 116628), ('this', 116478), ('me', 115295), ('their', 115284), ('many', 112912), ('than', 110061), ('find', 107829), ('time', 107074), ('india', 106549), ('more', 102588), ('but', 102314), ('money', 102062), ('someone', 100078), ('all', 99907), ('without', 97196), ('indian', 96303), ('other', 95886), ('new', 95702), ('want', 95235), ('become', 91086), ('think', 90352), ('better', 85382), ('first', 84387), ('start', 84243), ('ever', 82374), ('into', 82279), ('quora', 79965), ('take', 77569), ('out', 76810), (\"don't\", 73582), ('feel', 72579), ('he', 72556)]\n"
     ]
    }
   ],
   "source": [
    "print (words_freq_10000[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'to', 'of', 'and', 'india?', 'quora', 'quora?', 'why?', 'life?', 'it?', \"i'm\", 'do?', 'time?', 'me?', 'english?', '2016?', 'mean?', 'online?', 'work?', '?', '10', 'instagram', 'you?', '2016', 'world?', '500', 'them?', 'engineering?', '1000', 'weight?', 'money?', 'account?', 'like?', 'whatsapp', 'not?', 'exam?', 'for?', 'language?', 'possible?', 'this?', 'sentence?', 'people?', 'day?', 'phone?', '-', 'number?', 'us?', 'sydney?', 'skills?', 'now?', 'country?', 'sex?', 'so,', 'instagram?', 'system?', 'facebook?', 'in?', 'free?', 'university?', 'job?', 'business?', 'movies?', 'bangalore?', 'year?', 'from?', 'person?', 'love?', 'about?', '2017?', 'college?', 'company?', 'water?', 'u.s.', 'programming?', 'companies?', 'exist?', 'app?', 'china?', 'fat?', 'card?', 'website?', 'years?', 'youtube?', 'how?', 'delhi?', 'one?', 'have?', 'science?', '/', 'girl?', \"someone's\", 'usa?', '12', 'be?', 'school?', \"i've\", 'jio', 'interview?', 'snapchat', 'month?']\n"
     ]
    }
   ],
   "source": [
    "print (word_notin_word2vec[0:100])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'what', 'is', 'how', 'i', 'in', 'do', 'are', 'can', 'for', 'why', 'you', 'my', 'best', 'it', 'on', 'does', 'which', 'or', 'if', 'get', 'with', 'be', 'should', 'an', 'have', 'that', 'some', 'from', 'your', 'when', 'will', 'who', 'at', 'good', 'like', 'there', 'people', 'as', 'would', 'between', 'where', 'one', 'about', 'most', 'way', 'make', 'any', 'not', 'we', 'by', 'after', 'did', 'was', 'am', 'difference', 'they', 'has', 'much', \"what's\", 'so', 'learn', 'use', 'know', 'this', 'me', 'their', 'many', 'than', 'find', 'time', 'india', 'more', 'but', 'money', 'someone', 'all', 'without', 'indian', 'other', 'new', 'want', 'become', 'think', 'better', 'first', 'start', 'ever', 'into', 'take', 'out', \"don't\", 'feel', 'he', 'used', 'could', 'life', 'improve', 'possible', 'english']\n"
     ]
    }
   ],
   "source": [
    "print (word_in_word2vec[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Further Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^A-Za-z0-9^?,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\?\", \" \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    \n",
    "    text = text.split()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.reset_index(drop = True, inplace = True)\n",
    "X_valid.reset_index(drop = True, inplace = True)\n",
    "y_train.reset_index(drop = True, inplace = True)\n",
    "y_valid.reset_index(drop = True, inplace = True)\n",
    "\n",
    "X_train_df = pd.DataFrame()\n",
    "X_valid_df = pd.DataFrame()\n",
    "X_test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20128</td>\n",
       "      <td>37998</td>\n",
       "      <td>37999</td>\n",
       "      <td>How is the working environment at SBI Life, Mu...</td>\n",
       "      <td>How stressful is work of SBI clerk?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296237</td>\n",
       "      <td>418414</td>\n",
       "      <td>31812</td>\n",
       "      <td>How can a US citizen work in Canada?</td>\n",
       "      <td>Will a US graduate degree help a non-US citize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107095</td>\n",
       "      <td>176273</td>\n",
       "      <td>176274</td>\n",
       "      <td>What are the benefits of washing your hands wi...</td>\n",
       "      <td>Why is it important to wash your hands with soap?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0   20128   37998   37999  How is the working environment at SBI Life, Mu...   \n",
       "1  296237  418414   31812               How can a US citizen work in Canada?   \n",
       "2  107095  176273  176274  What are the benefits of washing your hands wi...   \n",
       "\n",
       "                                           question2  \n",
       "0                How stressful is work of SBI clerk?  \n",
       "1  Will a US graduate degree help a non-US citize...  \n",
       "2  Why is it important to wash your hands with soap?  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id                                          question1  \\\n",
       "0       0  How does the Surface Pro himself 4 compare wit...   \n",
       "1       1  Should I have a hair transplant at age 24? How...   \n",
       "2       2  What but is the best way to send money from Ch...   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', '=', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text('What is= the step by step guide to invest in?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'] = X_train['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_train_df['question2'] = X_train['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_df['question1'] = X_valid['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_df['question2'] = X_valid['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_test_df['question1'] = test_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_test_df['question2'] = test_df['question2'].apply(lambda x:preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[how, is, the, working, environment, at, sbi, ...</td>\n",
       "      <td>[how, stressful, is, work, of, sbi, clerk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, can, a, us, citizen, work, in, canada]</td>\n",
       "      <td>[will, a, us, graduate, degree, help, a, non, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[what, are, the, benefits, of, washing, your, ...</td>\n",
       "      <td>[why, is, it, important, to, wash, your, hands...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  [how, is, the, working, environment, at, sbi, ...   \n",
       "1       [how, can, a, us, citizen, work, in, canada]   \n",
       "2  [what, are, the, benefits, of, washing, your, ...   \n",
       "\n",
       "                                           question2  \n",
       "0         [how, stressful, is, work, of, sbi, clerk]  \n",
       "1  [will, a, us, graduate, degree, help, a, non, ...  \n",
       "2  [why, is, it, important, to, wash, your, hands...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283003,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df['question1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of words in X_train_df question 1 3143028\n",
      "Lenght of words after adding X_train_df question 2 6358368\n",
      "Lenght of words after adding X_valid_df question 1 7705257\n",
      "Lenght of words after adding X_valid_df question 2 9080346\n",
      "Lenght of words after adding X_test_df question 1 48938305\n",
      "Lenght of words after adding X_test_df question 2 88928769\n"
     ]
    }
   ],
   "source": [
    "words_list = create_vocabulary([],X_train_df,'question1')\n",
    "print (\"Lenght of words in X_train_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_train_df,'question2')\n",
    "print (\"Lenght of words after adding X_train_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question1')\n",
    "print (\"Lenght of words after adding X_valid_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question2')\n",
    "print (\"Lenght of words after adding X_valid_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question1')\n",
    "print (\"Lenght of words after adding X_test_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question2')\n",
    "print (\"Lenght of words after adding X_test_df question 2 {}\".format(len(words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131743\n",
      "['how', 'is', 'the', 'working', 'environment', 'at', 'sbi', 'life', 'mumbai', 'how']\n",
      "9206\n",
      "794\n"
     ]
    }
   ],
   "source": [
    "print (len(set(words_list)))\n",
    "print (words_list[0:10])\n",
    "words_freq = collections.Counter(words_list)\n",
    "words_freq.most_common(10)\n",
    "words_freq_10000 = words_freq.most_common(10000)\n",
    "\n",
    "\n",
    "word_in_word2vec = []\n",
    "word_notin_word2vec = []\n",
    "\n",
    "for word in words_freq.most_common(10000):\n",
    "    if word[0] in model.vocab:\n",
    "        word_in_word2vec.append(word[0])\n",
    "    else:\n",
    "        word_notin_word2vec.append(word[0])\n",
    "        \n",
    "print (len(word_in_word2vec))\n",
    "print (len(word_notin_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'to', 'of', 'and', '-', 'quora', '2016', '10', 'instagram', '500', '1000', 'whatsapp', '2017', '2015', 'snapchat', '20', ':', '12', '100', '000', '15', '30', '50', 'jio', '12th', 'sbi', '16', '11', 'brexit', '!', '18', 'upsc', 'ece', '13', 'tcs', 'narendra', 'better:', '2014', '25', '17', '14', '70', 'mbbs', 'manipal', '2000', 'gmat', '40', 'iim', '24', 'btech', 'cgpa', '200', 'iiit', 'cgl', '10th', 'obc', 'redmi', 'favourite', '90', '60', 'iits', '21', 'pilani', 'aiims', 'centre', 'mightn', '80', 'flipkart', 'mustn', 'xiaomi', '19', 'travelling', 'ielts', '22', '300', 'india:', 'bba', 'colour', 'ibps', '23', 'ps4', '2013', 'mtech', 'accenture', 'x^2', 'paytm', '25000', 'elon', 'hadoop', 'kohli', 'srm', 'kejriwal', 'bitsat', 'spotify', '11th', 'grey', \"'\", '32', 'ncr', 'virat']\n"
     ]
    }
   ],
   "source": [
    "print (word_notin_word2vec[0:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_index = {}\n",
    "index_to_words = {}\n",
    "\n",
    "i = 0\n",
    "for word in set(words_list):\n",
    "    words_to_index[word] = i\n",
    "    i = i + 1\n",
    "    \n",
    "j=0\n",
    "for word in set(words_list):\n",
    "    index_to_words[j] = word\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('words_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(words_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('index_to_words.pickle', 'wb') as handle:\n",
    "    pickle.dump(index_to_words, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14632\n",
      "131743\n",
      "diam\n",
      "levothyroxine\n"
     ]
    }
   ],
   "source": [
    "print (words_to_index['the'])\n",
    "print (len(words_to_index))\n",
    "print (index_to_words[104295])\n",
    "print (index_to_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72487, 100724, 14632, 121183, 66543, 114399]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_2_integer(wordslist):\n",
    "    question2integer = []\n",
    "    for word in wordslist:\n",
    "        question2integer.append(words_to_index[word])\n",
    "\n",
    "    return question2integer\n",
    "\n",
    "word_2_integer(['what', 'is', 'the', 'story', 'of', 'kohinoor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'] = X_train_df['question1'].apply(lambda x:word_2_integer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question2'] = X_train_df['question2'].apply(lambda x:word_2_integer(x))\n",
    "X_valid_df['question1'] = X_valid_df['question1'].apply(lambda x:word_2_integer(x))\n",
    "X_valid_df['question2'] = X_valid_df['question2'].apply(lambda x:word_2_integer(x))\n",
    "X_test_df['question1'] = X_test_df['question1'].apply(lambda x:word_2_integer(x))\n",
    "X_test_df['question2'] = X_test_df['question2'].apply(lambda x:word_2_integer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [62398, 100724, 14632, 93, 65626, 8375, 49702,...\n",
       "1    [62398, 48508, 78971, 87119, 54862, 72873, 410...\n",
       "2    [72487, 62225, 14632, 11156, 66543, 5548, 7760...\n",
       "3    [62398, 10287, 14632, 24307, 31939, 66543, 236...\n",
       "4    [100724, 14632, 112889, 23163, 65800, 128187, ...\n",
       "Name: question1, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df['question1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embed_length = 300\n",
    "embed_matrix = np.random.randn(len(words_to_index)+1,embed_length)\n",
    "# To ignore padding\n",
    "embed_matrix[0] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131744, 300)\n"
     ]
    }
   ],
   "source": [
    "print (embed_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.28003944e-01  1.54579331e+00 -3.83079812e-01 -8.36466124e-02\n",
      " -7.39653684e-01  1.46393452e-01  1.52999916e+00 -1.76033992e+00\n",
      " -3.98542902e-01  3.17350711e-02  8.24731838e-01  3.70434018e-02\n",
      " -2.28599266e-01 -5.19194792e-01  1.80413798e+00 -3.04626298e-01\n",
      " -1.10937024e+00 -9.37830008e-01 -7.49936143e-01  1.11140699e+00\n",
      "  7.10048587e-01  5.03501099e-01 -2.83290933e-01 -5.15819979e-01\n",
      " -1.00338804e+00  2.18563589e+00 -2.49315225e-01 -1.20536892e+00\n",
      " -4.44473838e-01  8.41733037e-01 -3.83638942e-03 -5.04689165e-01\n",
      "  5.32180596e-01 -2.98095953e-01 -2.93073026e+00  4.40414144e-01\n",
      "  1.47632395e+00  6.15557787e-01 -6.16197931e-01 -9.71731738e-01\n",
      "  9.47916680e-01  9.58477165e-01  2.42288950e-01 -1.73315113e+00\n",
      " -1.49556719e+00 -3.28203444e-01  1.06648372e+00  1.15324732e+00\n",
      " -2.38861136e-01  8.73026918e-01  1.04939494e+00 -3.50163012e-01\n",
      "  2.87915726e-02 -8.54624938e-01 -1.63895964e+00 -1.12389430e+00\n",
      " -7.30194390e-01 -5.16509667e-02  4.09188479e-01  9.26831636e-01\n",
      " -2.91892644e-01 -6.16139991e-01 -1.50356364e+00  1.10765777e+00\n",
      "  2.63792819e-03  7.27991320e-01  5.10821375e-01  7.10141768e-01\n",
      "  8.43426357e-01  1.07576259e+00  9.96727576e-02 -9.54845777e-01\n",
      "  7.51898463e-01 -8.11763062e-01  3.76915299e-01 -2.45304285e-01\n",
      "  3.12119038e-01 -1.18727131e+00 -2.44295690e+00 -3.15968009e-01\n",
      "  4.40505501e-01 -1.44268092e+00 -4.49919135e-01 -2.20862933e-01\n",
      " -9.52778094e-01 -1.47579025e+00  1.25037435e+00  3.92885165e-01\n",
      "  7.76755450e-01 -9.71814311e-01  1.50940088e-02 -1.80816437e+00\n",
      "  1.04540518e+00  1.18409691e+00 -1.23528831e+00  7.79537174e-01\n",
      " -2.31487866e-01 -2.04490824e+00  1.15637541e+00 -1.18819689e-01\n",
      " -1.62753609e+00  1.25904582e+00 -6.78085758e-01 -3.53095782e-01\n",
      " -5.37785363e-01 -1.21742710e+00  6.79973464e-01  1.29977285e+00\n",
      " -2.24782179e+00  8.30131710e-01 -8.65439449e-01 -1.73065365e-01\n",
      " -2.89317954e-01 -9.54576526e-01  1.40298380e+00 -3.74114063e-01\n",
      " -5.51836693e-01 -3.63505854e-01 -9.14526736e-01 -1.34006535e+00\n",
      " -1.83869365e+00 -3.33701900e-01  1.01100397e+00  1.11008823e-01\n",
      " -5.25514114e-01 -1.86735078e+00 -4.22241660e-01 -6.30777572e-02\n",
      " -9.87370745e-02  1.67102833e+00 -4.78640098e-02 -5.16504847e-01\n",
      " -2.93083941e+00  5.95547695e-01  1.19333997e+00 -6.14699551e-01\n",
      "  7.71521662e-01 -1.62236381e+00  5.22708100e-01 -5.49357362e-02\n",
      "  5.11451166e-01 -2.81222890e-01  3.31641019e-01 -1.19355520e+00\n",
      " -7.90913720e-01  6.20456095e-01 -1.85018577e+00  1.37522691e+00\n",
      " -1.60789639e+00 -6.27201128e-01  1.19437639e-02 -1.88586897e-01\n",
      "  1.44349893e+00  7.21723604e-01  1.37834580e+00  1.84940562e+00\n",
      " -9.45470341e-01 -2.69679145e-01 -7.36395869e-01 -1.67103571e+00\n",
      " -2.33997217e-01 -6.12200618e-01 -1.49963847e-01 -4.81583499e-01\n",
      " -2.68799719e-02  3.76248326e-01  3.55458634e-01  1.97017587e+00\n",
      " -1.38688785e+00  2.10228327e+00 -6.59759084e-01 -1.00596207e+00\n",
      "  4.65383106e-01  2.49979499e-01  1.47426465e+00 -4.59356355e-01\n",
      "  1.72468345e+00  3.88274581e-03 -2.93715177e-02 -1.09707662e+00\n",
      "  6.28005675e-02 -8.20644782e-01  2.87139128e-01 -3.56386229e-02\n",
      "  8.50448893e-01 -6.40608738e-01 -7.45028885e-02 -1.53547156e-02\n",
      "  8.60190307e-01  9.00613236e-01 -1.35538318e+00  7.13649245e-01\n",
      "  1.14898177e-01  6.16865439e-01 -3.32381365e-01  1.15663013e-01\n",
      " -3.88031497e-01  4.92528119e-01  5.72003680e-01  4.77908108e-01\n",
      "  9.50159519e-01  4.77813741e-01 -1.11165416e+00  5.90230925e-01\n",
      " -9.36364135e-01 -1.35455665e-01 -2.55444389e-01 -7.89601957e-01\n",
      " -1.45631416e+00 -8.87748332e-01  1.60212627e+00 -3.14779433e-03\n",
      " -1.58245221e+00  4.74836641e-01  1.77488711e+00  1.21166774e+00\n",
      "  3.73916461e-01  1.54605524e+00 -3.46904463e-01  1.40583514e+00\n",
      " -7.40359978e-02  9.55040526e-01  3.90623179e-01  4.02971539e-01\n",
      " -7.05470316e-01 -1.08187958e+00  1.57256707e+00  1.48686833e+00\n",
      "  8.17930338e-01 -2.73810872e-01  1.21925593e+00  1.27513232e+00\n",
      "  9.15710749e-01 -1.35053000e-01 -3.46970929e-02  1.37705110e+00\n",
      " -1.97122017e-01 -4.42163666e-01  7.82468767e-01  2.22949490e-01\n",
      " -1.22839084e+00  4.04850558e-01  1.48246368e+00 -1.10392726e+00\n",
      "  1.67784387e+00 -3.79145977e-01 -1.53440709e-01  8.17616434e-01\n",
      " -5.06887449e-01 -1.88700691e+00 -3.50785545e-01 -2.36882774e-01\n",
      "  9.69794067e-01 -1.32625564e-01 -1.10548726e-01 -1.16839440e+00\n",
      " -1.94459853e+00 -1.49505225e+00  1.80567581e+00 -5.76448704e-02\n",
      " -4.91917596e-01 -4.53224754e-01  1.83008444e-01  2.26291155e-01\n",
      " -2.93418958e-01 -7.39563205e-01  4.87205070e-01 -9.79926988e-01\n",
      "  1.10646326e-01 -1.34692832e-01 -5.55549780e-01  3.82032560e-01\n",
      "  1.28519437e+00  1.26310886e+00  2.83821243e+00  7.09449540e-01\n",
      " -4.99885079e-01 -3.67982011e-03  4.29398203e-01 -8.13068224e-01\n",
      " -5.57471879e-01 -8.78938656e-01  1.22318437e+00  1.83023680e+00\n",
      "  2.70031783e-01  8.81527697e-01  3.04846824e-01 -1.02521800e+00\n",
      " -8.70331418e-01 -2.60635548e+00 -5.96055900e-02 -6.00302637e-01\n",
      "  6.67816390e-01 -8.93577339e-01 -6.56454310e-01 -8.11921957e-01\n",
      " -8.11561349e-01  1.86301636e+00 -4.66112246e-01  6.48182542e-01]\n"
     ]
    }
   ],
   "source": [
    "print (embed_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58547\n"
     ]
    }
   ],
   "source": [
    "#Updating embedding matrix \n",
    "count = 0\n",
    "for word, index in words_to_index.items():\n",
    "    if word in model.vocab:\n",
    "        count = count + 1\n",
    "        embed_matrix[index] = model.word_vec(word)\n",
    "\n",
    "print (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131743\n"
     ]
    }
   ],
   "source": [
    "print (len(words_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_seq_length = max([\n",
    "max(list(X_train_df['question1'].map(lambda x: len(x)))),\n",
    "max(list(X_train_df['question2'].map(lambda x: len(x)))),\n",
    "max(list(X_valid_df['question1'].map(lambda x: len(x)))),\n",
    "max(list(X_valid_df['question2'].map(lambda x: len(x)))),\n",
    "max(list(X_test_df['question1'].map(lambda x: len(x)))),\n",
    "max(list(X_test_df['question2'].map(lambda x: len(x)))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n"
     ]
    }
   ],
   "source": [
    "print (max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert labels to their numpy representations\n",
    "Y_train =  y_train.values\n",
    "Y_valid =  y_valid.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (type(Y_train))\n",
    "print (type(Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print (Y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = utils.to_categorical(Y_train, num_classes=2)\n",
    "Y_valid = utils.to_categorical(Y_valid, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assert X_train_dict['left'].shape == X_train_dict['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assert len(X_train_dict['left']) == len(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#padding to max seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62398, 100724, 14632, 93, 65626, 8375, 49702, 93246, 102404]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df['question1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad_left_zeros(question_list,max_seq_length):\n",
    "    question_list = [0] * (max_seq_length - len(question_list)) + question_list\n",
    "    return question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len (pad_left_zeros([31586, 69984, 104295, 57112, 55384, 21628, 63296, 131479, 95639]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'] = X_train_df['question1'].apply(lambda x: pad_left_zeros(x,max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question2'] = X_train_df['question2'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_valid_df['question1'] = X_valid_df['question1'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_valid_df['question2'] = X_valid_df['question2'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_test_df['question1'] = X_test_df['question1'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_test_df['question2'] = X_test_df['question2'].apply(lambda x: pad_left_zeros(x,max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split to dicts\n",
    "X_train_dict = {'left': X_train_df['question1'], 'right': X_train_df['question2']}\n",
    "X_valid_dict = {'left': X_valid_df['question1'], 'right': X_valid_df['question2']}\n",
    "X_test_dict = {'left': X_test_df['question1'], 'right': X_test_df['question2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 300\n",
    "timesteps = 242\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "#Input None,max_seq_length,1\n",
    "\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(embed_matrix),\n",
    "                            embed_length,\n",
    "                            weights=[embed_matrix],\n",
    "                            input_length=max_seq_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(242), Dimension(300)])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "shared_lstm = LSTM(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)\n",
    "# python -c 'import keras; print(keras.__version__)'\n",
    "# python3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(64)])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can then concatenate the two vectors:\n",
    "merged_vector = keras.layers.concatenate([left_output,right_output], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And add a logistic regression on top\n",
    "predictions = Dense(2, activation='softmax')(merged_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dict['left'] = np.concatenate(X_train_dict['left']).reshape(X_train_dict['left'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283003, 242)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dict['left'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_dict['right'] = np.concatenate(X_train_dict['right']).reshape(X_train_dict['right'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283003, 242)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dict['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_dict['left'] = np.concatenate(X_valid_dict['left']).reshape(X_valid_dict['left'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_dict['right'] = np.concatenate(X_valid_dict['right']).reshape(X_valid_dict['right'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,  62398,  60989, 100724,  72873,  66543,\n",
       "        49702,  71300])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dict['right'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283003 samples, validate on 121287 samples\n",
      "Epoch 1/1\n",
      "283003/283003 [==============================] - 1401s 5ms/step - loss: 0.4629 - acc: 0.7781 - val_loss: 0.4987 - val_acc: 0.7582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x39663d438>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Model(inputs=[left_input, right_input], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "n_epoch = 1\n",
    "\n",
    "\n",
    "model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_model_input(input_questions,preprocess_text,words_to_index):\n",
    "\n",
    "    final_new_words_list = []\n",
    "\n",
    "    # i = 0\n",
    "    for words_list in input_questions:\n",
    "        new_words_list = []\n",
    "      \n",
    "        for word in preprocess_text(words_list):\n",
    "\n",
    "            if words_to_index.get(word):\n",
    "                new_words_list.append(words_to_index.get(word))\n",
    "             \n",
    "        final_new_words_list.append(np.array(pad_left_zeros(new_words_list,max_seq_length)))\n",
    "        \n",
    "         \n",
    "    return [final_new_words_list[0].reshape(1,max_seq_length), final_new_words_list[1].reshape(1,max_seq_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index):\n",
    "    y_prob = model.predict(preprocess_model_input(input_questions,preprocess_text,words_to_index),batch_size=1, verbose=0, steps=None)\n",
    "\n",
    "    print (\"The probabilities predicted by model for the question pair \\n {} for classes [0,1] are \\n {}\".format(input_questions,y_prob))\n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    print (\"The class that model predicted for the question pair \\n {} is {}\".format(input_questions,y_classes))\n",
    "    return y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probabilities predicted by model for the question pair \n",
      " ['What is the capital of India?', 'What is the capital of India?'] for classes [0,1] are \n",
      " [[0.489049   0.51095104]]\n",
      "The class that model predicted for the question pair \n",
      " ['What is the capital of India?', 'What is the capital of India?'] is [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_questions = [\"What is the capital of India?\", \"What is the capital of India?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probabilities predicted by model for the question pair \n",
      " ['How can I be a good geologist?', 'What should I do to be a great geologist?'] for classes [0,1] are \n",
      " [[0.2599712 0.7400288]]\n",
      "The class that model predicted for the question pair \n",
      " ['How can I be a good geologist?', 'What should I do to be a great geologist?'] is [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_questions = [\"How can I be a good geologist?\", \"What should I do to be a great geologist?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probabilities predicted by model for the question pair \n",
      " ['What is the best travel website in spain?', 'What is the best travel website?'] for classes [0,1] are \n",
      " [[0.17791672 0.8220833 ]]\n",
      "The class that model predicted for the question pair \n",
      " ['What is the best travel website in spain?', 'What is the best travel website?'] is [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_questions = [\"What is the best travel website in spain?\", \"What is the best travel website?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283003 samples, validate on 121287 samples\n",
      "Epoch 1/4\n",
      "283003/283003 [==============================] - 1397s 5ms/step - loss: 0.4463 - acc: 0.7884 - val_loss: 0.4950 - val_acc: 0.7637\n",
      "Epoch 2/4\n",
      "283003/283003 [==============================] - 1369s 5ms/step - loss: 0.4309 - acc: 0.7965 - val_loss: 0.5030 - val_acc: 0.7590\n",
      "Epoch 3/4\n",
      "283003/283003 [==============================] - 1363s 5ms/step - loss: 0.4171 - acc: 0.8045 - val_loss: 0.4995 - val_acc: 0.7681\n",
      "Epoch 4/4\n",
      "283003/283003 [==============================] - 1365s 5ms/step - loss: 0.4040 - acc: 0.8118 - val_loss: 0.5075 - val_acc: 0.7662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x39658c518>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_epoch = 4\n",
    "\n",
    "\n",
    "model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283003 samples, validate on 121287 samples\n",
      "Epoch 1/6\n",
      "283003/283003 [==============================] - 1370s 5ms/step - loss: 0.3923 - acc: 0.8190 - val_loss: 0.5079 - val_acc: 0.7682\n",
      "Epoch 2/6\n",
      "283003/283003 [==============================] - 1364s 5ms/step - loss: 0.3805 - acc: 0.8247 - val_loss: 0.5143 - val_acc: 0.7675\n",
      "Epoch 3/6\n",
      "283003/283003 [==============================] - 1369s 5ms/step - loss: 0.3703 - acc: 0.8305 - val_loss: 0.5243 - val_acc: 0.7667\n",
      "Epoch 4/6\n",
      "283003/283003 [==============================] - 1370s 5ms/step - loss: 0.3606 - acc: 0.8354 - val_loss: 0.5327 - val_acc: 0.7630\n",
      "Epoch 5/6\n",
      "283003/283003 [==============================] - 1371s 5ms/step - loss: 0.3507 - acc: 0.8411 - val_loss: 0.5373 - val_acc: 0.7673\n",
      "Epoch 6/6\n",
      "283003/283003 [==============================] - 1370s 5ms/step - loss: 0.3417 - acc: 0.8461 - val_loss: 0.5450 - val_acc: 0.7677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x39663b630>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_epoch = 6\n",
    "\n",
    "\n",
    "model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283003 samples, validate on 121287 samples\n",
      "Epoch 1/5\n",
      "283003/283003 [==============================] - 1369s 5ms/step - loss: 0.3332 - acc: 0.8503 - val_loss: 0.5577 - val_acc: 0.7631\n",
      "Epoch 2/5\n",
      "189312/283003 [===================>..........] - ETA: 7:49 - loss: 0.3185 - acc: 0.8571"
     ]
    }
   ],
   "source": [
    "n_epoch = 5\n",
    "\n",
    "\n",
    "model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_questions = [\"What is the capital of India?\", \"What is the capital of India?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_questions = [\"How can I be a good geologist?\", \"What should I do to be a great geologist?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_questions = [\"What is the best travel website in spain?\", \"What is the best travel website?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_epoch = 4\n",
    "# training_start_time = time()\n",
    "\n",
    "# model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "#          validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))\n",
    "\n",
    "# print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_epoch = 20\n",
    "# training_start_time = time()\n",
    "\n",
    "# model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "#          validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))\n",
    "\n",
    "# print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "# # save the tokenizer and model\n",
    "# with open(\"keras_tokenizer.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(tokenizer, f)\n",
    "model.save(\"quora_keras_model_v1_tokenizer.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('words_to_index.pickle', 'rb') as handle:\n",
    "    words_to_index_1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('index_to_words.pickle', 'rb') as handle:\n",
    "    index_to_words_1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(words_to_index_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(index_to_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (index_to_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newtexts = [\"How do I read and find my YouTube comments?\", \"How can I see all my Youtube comments?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (newtexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "final_new_words_list = []\n",
    "print (new_words_list)\n",
    "i = 0\n",
    "for words_list in newtexts:\n",
    "    new_words_list = []\n",
    "    print (words_list)\n",
    "    for word in preprocess_text(words_list):\n",
    "        print (word)\n",
    "        if words_to_index_1.get(word):\n",
    "            \n",
    "            new_words_list.append(words_to_index_1.get(word))\n",
    "        else:\n",
    "            print (word)\n",
    "    final_new_words_list.append(np.array(pad_left_zeros(new_words_list,max_seq_length)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (final_new_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "predict_model = load_model(\"quora_keras_model_v1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_prob = predict_model.predict([final_new_words_list[0].reshape(1,max_seq_length), final_new_words_list[1].reshape(1,max_seq_length)],batch_size=1, verbose=1, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1rnn = Sequential()\n",
    "s1rnn.add(embedding_layer_1)\n",
    "s1rnn.add(LSTM(128, input_shape=(100, 1)))\n",
    "s1rnn.add(Dense(1))\n",
    "\n",
    "s2rnn = Sequential()\n",
    "s2rnn.add(embedding_layer_2)\n",
    "s2rnn.add(LSTM(128, input_shape=(100, 1)))\n",
    "s2rnn.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_baseline_text(X_train['question1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re.sub(r\"[^A-Za-z0-9,!.\\/'+-=]\", \" \", 'why am i mentally very lonely? how can i solve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re.sub(r\"\\'s\", \" \", 'what\\'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# words_list = []\n",
    "# # train_subset_df = train_df['question1'][0:10]\n",
    "# train_subset_df['question1'] = pd.DataFrame(data=train_df['question1'][0:10], columns=['question1'])\n",
    "# train_subset_df['question2'] = pd.DataFrame(data=train_df['question2'][0:10], columns=['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for sentence in train_subset_df['question1']:\n",
    "#     for word in sentence:\n",
    "#         words_list.append(word)\n",
    "# print (len(set(words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature based on how many words are common in question 1 and question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# u.termfrequency(['What is the step by step guide to invest in share market in india?'], ['What is the step by step guide to invest in share market?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def termfrequency(sentence1, sentence2):\n",
    "   \n",
    "    question_dict ={}\n",
    "    sentence1_words = sentence1   \n",
    "    sentence2_words = sentence2\n",
    "    searchtermfreq = []\n",
    "    i = 0\n",
    "    \n",
    "    for key in sentence1_words:\n",
    "#         print (key)\n",
    "        question_dict[key] = question_dict.get(key,0) + 1\n",
    "    \n",
    "    for key in set(sentence2_words):\n",
    "        value =  question_dict.get(key,0)\n",
    "        if value >= 1:\n",
    "            value = 1\n",
    "        searchtermfreq.append(value)\n",
    "        \n",
    "    \n",
    "#     print (question_dict)\n",
    "#     print (searchtermfreq)\n",
    "#     print (sum(searchtermfreq))\n",
    "    return sum(searchtermfreq)\n",
    "\n",
    "termfrequency(['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india?'], ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market?'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['common_term_freq'] = X_train_df.apply(lambda x: termfrequency(x['question1'],x['question2']), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_df['common_term_freq'] = X_valid_df.apply(lambda x: termfrequency(x['question1'],x['question2']), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_valid_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_words_freq(sentence):\n",
    "    return len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_words_freq(['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question1_words_freq'] = X_train_df['question1'].map(lambda x: total_words_freq(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question2_words_freq'] = X_train_df['question2'].map(lambda x: total_words_freq(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_df['question1_words_freq'] = X_valid_df['question1'].map(lambda x: total_words_freq(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_df['question2_words_freq'] = X_valid_df['question2'].map(lambda x: total_words_freq(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_valid_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_model_input = X_train_df.drop(['question1','question2'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_model_input = X_valid_df.drop(['question1','question2'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_model_input.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train a model# Train  \n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print (\"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf =  LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_classifier(clf, X_train_model_input, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def predict_labels(clf, X_train, y_train):\n",
    "    print (\"Predicting labels using {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nPrediction time (secs): {:.3f}\".format(end - start))\n",
    "    return log_loss(y_train, y_pred, eps=1e-15), confusion_matrix(y_train, y_pred)\n",
    "\n",
    "train_metrics = predict_labels(clf, X_train_model_input, y_train.values.ravel())\n",
    "\n",
    "print \n",
    "print (\"Log loss for training set: {}\".format(train_metrics[0]))\n",
    "\n",
    "print (\"Confusion matrix for training set: {}\".format(train_metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "print (\"Log loss for validation set: {}\".format(predict_labels(clf, X_valid_model_input, y_valid.values.ravel())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print (\"Confusion matrix for validation set: {}\".format(predict_labels(clf, X_valid_model_input, y_valid.values.ravel())[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_list = create_vocabulary([],X_train_df,'question1')\n",
    "print (\"Lenght of words in X_train_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_train_df,'question2')\n",
    "print (\"Lenght of words after adding X_train_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question1')\n",
    "print (\"Lenght of words after adding X_valid_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question2')\n",
    "print (\"Lenght of words after adding X_valid_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question1')\n",
    "print (\"Lenght of words after adding X_test_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question2')\n",
    "print (\"Lenght of words after adding X_test_df question 2 {}\".format(len(words_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(list_words):\n",
    "     list_words_processed = []\n",
    "     for text in list_words:\n",
    "         text = re.sub(r\"\\?\", '', text)\n",
    "         text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#          print (text)\n",
    "         list_words_processed.append(str(text))\n",
    "#          print (list_words_processed)\n",
    "     return list_words_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text(['India?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text(['how',\n",
    " 'do',\n",
    " 'the',\n",
    " 'holy',\n",
    " 'scriptures',\n",
    " 'of',\n",
    " 'hinduism',\n",
    " 'compare',\n",
    " 'and',\n",
    " 'contrast',\n",
    " 'to',\n",
    " 'those',\n",
    " 'of',\n",
    " 'taoism?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text(X_train_df['question1'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_p_df = pd.DataFrame()\n",
    "X_valid_p_df = pd.DataFrame()\n",
    "X_test_p_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_p_df['question1'] = X_train_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_train_p_df['question2'] = X_train_df['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_p_df['question1'] = X_valid_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_p_df['question2'] = X_valid_df['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_test_p_df['question1'] = X_test_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_test_p_df['question2'] = X_test_df['question2'].apply(lambda x:preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_p_df['question1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_words_list = create_vocabulary([],X_train_p_df,'question1')\n",
    "print (\"Lenght of words in X_train_df question 1 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_train_p_df,'question2')\n",
    "print (\"Lenght of words after adding X_train_df question 2 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_valid_p_df,'question1')\n",
    "print (\"Lenght of words after adding X_valid_df question 1 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_valid_p_df,'question2')\n",
    "print (\"Lenght of words after adding X_valid_df question 2 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_test_p_df,'question1')\n",
    "print (\"Lenght of words after adding X_test_df question 1 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_test_p_df,'question2')\n",
    "print (\"Lenght of words after adding X_test_df question 2 {}\".format(len(words_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_words_freq = collections.Counter(proc_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_words_freq_10000 = proc_words_freq.most_common(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_word_in_word2vec = []\n",
    "proc_word_notin_word2vec = []\n",
    "\n",
    "for word in proc_words_freq.most_common(10000):\n",
    "    if word[0] in model.vocab:\n",
    "        proc_word_in_word2vec.append(word[0])\n",
    "    else:\n",
    "        proc_word_notin_word2vec.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(proc_word_in_word2vec))\n",
    "print (len(proc_word_notin_word2vec))\n",
    "print (proc_word_notin_word2vec[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (proc_word_in_word2vec[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "quoravenv",
   "language": "python",
   "name": "quoravenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
