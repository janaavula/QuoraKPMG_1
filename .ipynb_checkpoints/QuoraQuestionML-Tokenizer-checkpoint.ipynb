{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Question Pairs Competition Notebook\n",
    "\n",
    "### To Improve User (question seeker, answer writer) Satisfaction by buidling a model to improve model performance of low log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing modules and Loading word2vec pretrained embedding vector\n",
      "keras version is 2.1.2\n",
      "tf version is 1.4.1\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import utilities as u\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import collections\n",
    "import keras\n",
    "import tensorflow as tf;\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "#Check Keras and tensorflow version\n",
    "print (\"Importing modules and Loading word2vec pretrained embedding vector\")\n",
    "print(\"keras version is {}\".format(keras.__version__))\n",
    "print(\"tf version is {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jac812i/virtualenvs/quoravenv/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071)]\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained embedding vector trained on Google News\n",
    "EMBEDDING_FILE = '../GoogleNews-vectors-negative300.bin.gz'\n",
    "model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "# To check if word2vec embedding model is loaded succesfully\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jac812i/virtualenvs/quoravenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read training and test data from .csv files\n",
    "train_df = pd.read_csv(\"../train.csv\")\n",
    "test_df = pd.read_csv(\"../test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display top 3 rows of train data\n",
    "train_df.head(3)\n",
    "# assert the shape of train dataframe\n",
    "assert train_df.shape[0] > 0\n",
    "assert train_df.shape[1] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display top 3 rows of test data and assert test data shape\n",
    "test_df.head(3)\n",
    "assert test_df.shape[0] > 0\n",
    "assert test_df.shape[1] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Feature and Target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns ['id', 'qid1', 'qid2', 'question1', 'question2']\n",
      "Target Columns is_duplicate\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(train_df.columns[:-1])\n",
    "target_col = train_df.columns[-1]\n",
    "print (\"Feature Columns {}\".format(feature_cols))\n",
    "print (\"Target Columns {}\".format(target_col))\n",
    "X_all = train_df[feature_cols]\n",
    "y_all = pd.DataFrame(data=train_df[target_col], columns=[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 255027, 1: 149263})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if the data is balanced or not\n",
    "collections.Counter(y_all['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the 5 rows of train output\n",
    "y_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the 3 rows of the new dataframe\n",
    "X_all.head(3)\n",
    "# Assert the shapes are equal after removing the feature\n",
    "assert X_all.shape == (train_df.shape[0],train_df.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data in training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data set: 404290 samples\n",
      "Training set: 283003 samples\n",
      "Valid set: 121287 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data into 70% training and 30% validation and have a constant random state so that the results are consistent\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, test_size=0.30, random_state=42)\n",
    "print (\"Total data set: {} samples\".format(X_all.shape[0]))\n",
    "print (\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print (\"Valid set: {} samples\".format(X_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# asserting the shapes after splitting the data\n",
    "assert (X_train.shape[0] + X_valid.shape[0]) == X_all.shape[0]\n",
    "assert (y_train.shape[0] + y_valid.shape[0]) == y_all.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 178677, 1: 104326})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO check how many question pairs in training set are duplicate or not\n",
    "collections.Counter(y_train['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 76350, 1: 44937})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO check how many question pairs in validation set are duplicate or not\n",
    "collections.Counter(y_valid['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "\n",
       "                                                question2  \n",
       "8067                   How do I play Pokémon GO in China?  \n",
       "368101  What are some good side dishes for buffalo chi...  \n",
       "70497       What is the best server setup for buddypress?  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Check few rows of X_valid\n",
    "X_valid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate\n",
       "8067               0\n",
       "368101             0\n",
       "70497              0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check few rows of y_valid\n",
    "y_valid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset index to start from 0\n",
    "X_train.reset_index(drop = True, inplace = True)\n",
    "X_valid.reset_index(drop = True, inplace = True)\n",
    "y_train.reset_index(drop = True, inplace = True)\n",
    "y_valid.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#asserting shapes after resetting index\n",
    "assert (X_train.shape[0] + X_valid.shape[0]) == X_all.shape[0]\n",
    "assert (y_train.shape[0] + y_valid.shape[0]) == y_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0    8067   15738   15739                 How do I play Pokémon GO in Korea?   \n",
       "1  368101   12736  104117  What are some of the best side dishes for crab...   \n",
       "2   70497  121486  121487  Which is more advisable and better material fo...   \n",
       "\n",
       "                                           question2  \n",
       "0                 How do I play Pokémon GO in China?  \n",
       "1  What are some good side dishes for buffalo chi...  \n",
       "2      What is the best server setup for buddypress?  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Check few rows of X_valid\n",
    "X_valid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Data Preprocessing for Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function that takes a text and preprocess it like converting to string, split the string etc\n",
    "\n",
    "def preprocess_baseline_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "#Test the function\n",
    "assert preprocess_baseline_text('How do I play Pokémon GO in Korea?') == ['how', 'do', 'i', 'play', 'pokémon', 'go', 'in', 'korea?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id   qid1   qid2                           question1  \\\n",
      "0  8067  15738  15739  How do I play Pokémon GO in Korea?   \n",
      "\n",
      "                            question2  \n",
      "0  How do I play Pokémon GO in China?  \n"
     ]
    }
   ],
   "source": [
    "print (X_valid[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function that returns a list of all the words from a dataframe\n",
    "\n",
    "def create_vocabulary(words_list,df,column_name):\n",
    "    for sentence in df[column_name]:\n",
    "        for word in sentence:\n",
    "            words_list.append(word)\n",
    "    return words_list\n",
    "\n",
    "\n",
    "#Test the function\n",
    "data = [['How do I play Pokémon GO in Korea?']]\n",
    "test_sub_df = pd.DataFrame(data,columns=['question1'])\n",
    "test_sub_df['question1'] = test_sub_df['question1'].apply(lambda x: preprocess_baseline_text(x))\n",
    "\n",
    "# assert the function is working fine with dataframe and column name\n",
    "assert create_vocabulary([],test_sub_df,'question1') == ['how', 'do', 'i', 'play', 'pokémon', 'go', 'in', 'korea?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new dataframes and do data preprocessing on the question1 and question 2 columns\n",
    "X_train_df = pd.DataFrame()\n",
    "X_valid_df = pd.DataFrame()\n",
    "X_train_df['question1'] = X_train['question1'].apply(lambda x:preprocess_baseline_text(x))\n",
    "X_train_df['question2'] = X_train['question2'].apply(lambda x:preprocess_baseline_text(x))\n",
    "X_valid_df['question1'] = X_valid['question1'].apply(lambda x:preprocess_baseline_text(x))\n",
    "X_valid_df['question2'] = X_valid['question2'].apply(lambda x:preprocess_baseline_text(x))\n",
    "\n",
    "#assertions on dataframe shape's\n",
    "assert X_train_df.shape[0] == X_train.shape[0]\n",
    "assert X_train_df.shape[1] == 2\n",
    "assert X_valid_df.shape[0] == X_valid_df.shape[0]\n",
    "assert X_valid_df.shape[1] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[how, is, the, working, environment, at, sbi, ...</td>\n",
       "      <td>[how, stressful, is, work, of, sbi, clerk?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, can, a, us, citizen, work, in, canada?]</td>\n",
       "      <td>[will, a, us, graduate, degree, help, a, non-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[what, are, the, benefits, of, washing, your, ...</td>\n",
       "      <td>[why, is, it, important, to, wash, your, hands...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  [how, is, the, working, environment, at, sbi, ...   \n",
       "1      [how, can, a, us, citizen, work, in, canada?]   \n",
       "2  [what, are, the, benefits, of, washing, your, ...   \n",
       "\n",
       "                                           question2  \n",
       "0        [how, stressful, is, work, of, sbi, clerk?]  \n",
       "1  [will, a, us, graduate, degree, help, a, non-u...  \n",
       "2  [why, is, it, important, to, wash, your, hands...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check few rows of dataframe for manual validation\n",
    "X_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[how, do, i, play, pokémon, go, in, korea?]</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, china?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[what, are, some, of, the, best, side, dishes,...</td>\n",
       "      <td>[what, are, some, good, side, dishes, for, buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[which, is, more, advisable, and, better, mate...</td>\n",
       "      <td>[what, is, the, best, server, setup, for, budd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0        [how, do, i, play, pokémon, go, in, korea?]   \n",
       "1  [what, are, some, of, the, best, side, dishes,...   \n",
       "2  [which, is, more, advisable, and, better, mate...   \n",
       "\n",
       "                                           question2  \n",
       "0        [how, do, i, play, pokémon, go, in, china?]  \n",
       "1  [what, are, some, good, side, dishes, for, buf...  \n",
       "2  [what, is, the, best, server, setup, for, budd...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check few rows of dataframe for manual validation\n",
    "X_valid_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words after adding training data question 1 4423826\n",
      "Length of words after adding training data question 2 8944593\n",
      "Length of words after adding test data question 1 48146246\n",
      "Length of words after adding test data question 2 87470531\n"
     ]
    }
   ],
   "source": [
    "# Create complete vocabulary from all the data using training and test data.\n",
    "\n",
    "words_list = create_vocabulary([],X_all_1,'question1')\n",
    "print (\"Length of words after adding training data question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_all_1,'question2')\n",
    "print (\"Length of words after adding training data question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,test_df_1,'question1')\n",
    "print (\"Length of words after adding test data question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,test_df_1,'question2')\n",
    "print (\"Length of words after adding test data question 2 {}\".format(len(words_list)))\n",
    "\n",
    "# asserting to check words list calculation did not provide empty records\n",
    "assert len(words_list) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple baseline model with Logistic Regression\n",
    "###    Create a feature based on how many words are common in question 1 and question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate how many unique words are common between two question sentence's\n",
    "def termfrequency(sentence1, sentence2):\n",
    "   \n",
    "    question_dict ={}\n",
    "    sentence1_words = sentence1   \n",
    "    sentence2_words = sentence2\n",
    "    searchtermfreq = []\n",
    "    \n",
    "    for key in sentence1_words:\n",
    "        question_dict[key] = question_dict.get(key,0) + 1\n",
    "    \n",
    "    for key in set(sentence2_words):\n",
    "        value =  question_dict.get(key,0)\n",
    "        if value >= 1:\n",
    "            value = 1\n",
    "        searchtermfreq.append(value)\n",
    "        \n",
    "    return sum(searchtermfreq)\n",
    "\n",
    "\n",
    "#assertion to make sure term frequency function is working fine\n",
    "assert termfrequency(['what', 'is', 'the', 'step', 'by', 'step'], ['what', 'is', 'the', 'step', 'by', 'step', 'guide']) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a new column common_term_freq which has the value of unique words that are common between two question sentence's\n",
    "\n",
    "X_train_df['common_term_freq'] = X_train_df.apply(lambda x: termfrequency(x['question1'],x['question2']), axis=1 )\n",
    "X_valid_df['common_term_freq'] = X_valid_df.apply(lambda x: termfrequency(x['question1'],x['question2']), axis=1 )\n",
    "\n",
    "# assert to make sure the column is a number\n",
    "assert X_train_df['common_term_freq'].shape[0] == X_train_df.shape[0]\n",
    "assert X_valid_df['common_term_freq'].shape[0] == X_valid_df.shape[0]\n",
    "assert X_train_df['common_term_freq'][0] >- 0\n",
    "assert X_valid_df['common_term_freq'][0] >- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features based on Total words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to calculate count of number of words in a sentence\n",
    "def total_words_freq(sentence):\n",
    "    return len(sentence)\n",
    "\n",
    "assert total_words_freq(['what', 'is', 'the', 'step', 'by', 'step']) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create two new column's question1_words_freq and question2_words_freq using the above function \n",
    "#to calculate count of number of words in a sentence \n",
    "\n",
    "X_train_df['question1_words_freq'] = X_train_df['question1'].map(lambda x: total_words_freq(x))\n",
    "X_train_df['question2_words_freq'] = X_train_df['question2'].map(lambda x: total_words_freq(x))\n",
    "\n",
    "X_valid_df['question1_words_freq'] = X_valid_df['question1'].map(lambda x: total_words_freq(x))\n",
    "X_valid_df['question2_words_freq'] = X_valid_df['question2'].map(lambda x: total_words_freq(x))\n",
    "\n",
    "\n",
    "# assert to make sure the column is a number\n",
    "assert X_train_df['question1_words_freq'][0] >= 0\n",
    "assert X_train_df['question2_words_freq'][0] >= 0\n",
    "assert X_valid_df['question1_words_freq'][0] >= 0\n",
    "assert X_valid_df['question2_words_freq'][0] >= 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>common_term_freq</th>\n",
       "      <th>question1_words_freq</th>\n",
       "      <th>question2_words_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[how, is, the, working, environment, at, sbi, ...</td>\n",
       "      <td>[how, stressful, is, work, of, sbi, clerk?]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, can, a, us, citizen, work, in, canada?]</td>\n",
       "      <td>[will, a, us, graduate, degree, help, a, non-u...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[what, are, the, benefits, of, washing, your, ...</td>\n",
       "      <td>[why, is, it, important, to, wash, your, hands...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  [how, is, the, working, environment, at, sbi, ...   \n",
       "1      [how, can, a, us, citizen, work, in, canada?]   \n",
       "2  [what, are, the, benefits, of, washing, your, ...   \n",
       "\n",
       "                                           question2  common_term_freq  \\\n",
       "0        [how, stressful, is, work, of, sbi, clerk?]                 3   \n",
       "1  [will, a, us, graduate, degree, help, a, non-u...                 7   \n",
       "2  [why, is, it, important, to, wash, your, hands...                 4   \n",
       "\n",
       "   question1_words_freq  question2_words_freq  \n",
       "0                     9                     7  \n",
       "1                     8                    20  \n",
       "2                    10                    10  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check few rows\n",
    "X_train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>common_term_freq</th>\n",
       "      <th>question1_words_freq</th>\n",
       "      <th>question2_words_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[how, do, i, play, pokémon, go, in, korea?]</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, china?]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[what, are, some, of, the, best, side, dishes,...</td>\n",
       "      <td>[what, are, some, good, side, dishes, for, buf...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[which, is, more, advisable, and, better, mate...</td>\n",
       "      <td>[what, is, the, best, server, setup, for, budd...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0        [how, do, i, play, pokémon, go, in, korea?]   \n",
       "1  [what, are, some, of, the, best, side, dishes,...   \n",
       "2  [which, is, more, advisable, and, better, mate...   \n",
       "\n",
       "                                           question2  common_term_freq  \\\n",
       "0        [how, do, i, play, pokémon, go, in, china?]                 7   \n",
       "1  [what, are, some, good, side, dishes, for, buf...                 6   \n",
       "2  [what, is, the, best, server, setup, for, budd...                 2   \n",
       "\n",
       "   question1_words_freq  question2_words_freq  \n",
       "0                     8                     8  \n",
       "1                    11                     9  \n",
       "2                    16                     8  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check few rows\n",
    "X_valid_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop column's question1 and question2 since machine learning input requires columns with numbers\n",
    "X_train_model_input = X_train_df.drop(['question1','question2'],axis =1)\n",
    "X_valid_model_input = X_valid_df.drop(['question1','question2'],axis =1)\n",
    "\n",
    "assert X_train_model_input.shape[1] == X_train_df.shape[1] - 2\n",
    "assert X_valid_model_input.shape[1] == X_valid_df.shape[1] - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print (\"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "clf =  LogisticRegression()\n",
    "\n",
    "train_classifier(clf, X_train_model_input, y_train.values.ravel())\n",
    "\n",
    "\n",
    "\n",
    "def predict_labels(clf, X_train, y_train):\n",
    "    print (\"Predicting labels using {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nPrediction time (secs): {:.3f}\".format(end - start))\n",
    "    return log_loss(y_train, y_pred, eps=1e-15), confusion_matrix(y_train, y_pred)\n",
    "\n",
    "train_metrics = predict_labels(clf, X_train_model_input, y_train.values.ravel())\n",
    "\n",
    "print \n",
    "print (\"Log loss for training set: {}\".format(train_metrics[0]))\n",
    "\n",
    "print (\"Confusion matrix for training set: {}\".format(train_metrics[1]))\n",
    "\n",
    "# Predict on test data\n",
    "print (\"Log loss for validation set: {}\".format(predict_labels(clf, X_valid_model_input, y_valid.values.ravel())[0]))\n",
    "\n",
    "print (\"Confusion matrix for validation set: {}\".format(predict_labels(clf, X_valid_model_input, y_valid.values.ravel())[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check how many top frequent 10000 words in complete vocabulary are in word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To check how many top frequent 10000 words in complete vocabulary are in word2vec after basic preprocessing of text\n",
    "\n",
    "print (\"Total count of unique words in vocabulary {}\".format(len(set(words_list)))\n",
    "# print (words_list[0:10])\n",
    "words_freq = collections.Counter(words_list)\n",
    "words_freq.most_common(10)\n",
    "words_freq_10000 = words_freq.most_common(10000)\n",
    "\n",
    "\n",
    "word_in_word2vec = []\n",
    "word_notin_word2vec = []\n",
    "\n",
    "for word in words_freq.most_common(10000):\n",
    "    if word[0] in model.vocab:\n",
    "        word_in_word2vec.append(word[0])\n",
    "    else:\n",
    "        word_notin_word2vec.append(word[0])\n",
    "        \n",
    "print (\"Out of 10000 top frequent words {} words are present in word2vec after basic preprocessing of text\".format(len(word_in_word2vec)))\n",
    "print (\"Out of 10000 top frequent words {} words are not present in word2vec after basic preprocessing of text\".format(len(word_notin_word2vec)))\n",
    "\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print (\"Top 100 words from hightly frequent words in vocabulary present in word2vec {}\".format(words_freq_10000[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Top 100 words from hightly frequent words in vocabulary not present in word2vec {} {}\".format(word_notin_word2vec[0:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"List the first 100 words present that are present in vocabulary and in word2vec\")\n",
    "print (word_in_word2vec[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Further Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As you can see from above there are many words that are not present in word2vec and some of them are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^A-Za-z0-9^?,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\?\", \" \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    \n",
    "    text = text.split()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_df = pd.DataFrame()\n",
    "X_valid_df = pd.DataFrame()\n",
    "X_test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text('What is= the step by step guide to invest in?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'] = X_train['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_train_df['question2'] = X_train['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_df['question1'] = X_valid['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_df['question2'] = X_valid['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_test_df['question1'] = test_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_test_df['question2'] = test_df['question2'].apply(lambda x:preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_list = create_vocabulary([],X_train_df,'question1')\n",
    "print (\"Lenght of words in X_train_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_train_df,'question2')\n",
    "print (\"Lenght of words after adding X_train_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question1')\n",
    "print (\"Lenght of words after adding X_valid_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question2')\n",
    "print (\"Lenght of words after adding X_valid_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question1')\n",
    "print (\"Lenght of words after adding X_test_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question2')\n",
    "print (\"Lenght of words after adding X_test_df question 2 {}\".format(len(words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(set(words_list)))\n",
    "print (words_list[0:10])\n",
    "words_freq = collections.Counter(words_list)\n",
    "words_freq.most_common(10)\n",
    "words_freq_10000 = words_freq.most_common(10000)\n",
    "\n",
    "\n",
    "word_in_word2vec = []\n",
    "word_notin_word2vec = []\n",
    "\n",
    "for word in words_freq.most_common(10000):\n",
    "    if word[0] in model.vocab:\n",
    "        word_in_word2vec.append(word[0])\n",
    "    else:\n",
    "        word_notin_word2vec.append(word[0])\n",
    "        \n",
    "print (len(word_in_word2vec))\n",
    "print (len(word_notin_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (word_notin_word2vec[0:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_index = {}\n",
    "index_to_words = {}\n",
    "\n",
    "i = 0\n",
    "for word in set(words_list):\n",
    "    words_to_index[word] = i\n",
    "    i = i + 1\n",
    "    \n",
    "j=0\n",
    "for word in set(words_list):\n",
    "    index_to_words[j] = word\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('words_to_index_v2.pickle', 'wb') as handle:\n",
    "    pickle.dump(words_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('index_to_words_v2.pickle', 'wb') as handle:\n",
    "    pickle.dump(index_to_words, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (words_to_index['the'])\n",
    "print (len(words_to_index))\n",
    "print (index_to_words[104295])\n",
    "print (index_to_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_2_integer(wordslist):\n",
    "    question2integer = []\n",
    "    for word in wordslist:\n",
    "        question2integer.append(words_to_index[word])\n",
    "\n",
    "    return question2integer\n",
    "\n",
    "word_2_integer(['what', 'is', 'the', 'story', 'of', 'kohinoor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'] = X_train_df['question1'].apply(lambda x:word_2_integer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question2'] = X_train_df['question2'].apply(lambda x:word_2_integer(x))\n",
    "X_valid_df['question1'] = X_valid_df['question1'].apply(lambda x:word_2_integer(x))\n",
    "X_valid_df['question2'] = X_valid_df['question2'].apply(lambda x:word_2_integer(x))\n",
    "X_test_df['question1'] = X_test_df['question1'].apply(lambda x:word_2_integer(x))\n",
    "X_test_df['question2'] = X_test_df['question2'].apply(lambda x:word_2_integer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embed_length = 300\n",
    "embed_matrix = np.random.randn(len(words_to_index)+1,embed_length)\n",
    "# To ignore padding\n",
    "embed_matrix[0] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (embed_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (embed_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Updating embedding matrix \n",
    "count = 0\n",
    "for word, index in words_to_index.items():\n",
    "    if word in model.vocab:\n",
    "        count = count + 1\n",
    "        embed_matrix[index] = model.word_vec(word)\n",
    "\n",
    "print (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(words_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_seq_length = max([\n",
    "max(list(X_train_df['question1'].map(lambda x: len(x)))),\n",
    "max(list(X_train_df['question2'].map(lambda x: len(x)))),\n",
    "max(list(X_valid_df['question1'].map(lambda x: len(x)))),\n",
    "max(list(X_valid_df['question2'].map(lambda x: len(x)))),\n",
    "max(list(X_test_df['question1'].map(lambda x: len(x)))),\n",
    "max(list(X_test_df['question2'].map(lambda x: len(x)))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert labels to their numpy representations\n",
    "Y_train =  y_train.values\n",
    "Y_valid =  y_valid.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (type(Y_train))\n",
    "print (type(Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (Y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = utils.to_categorical(Y_train, num_classes=2)\n",
    "Y_valid = utils.to_categorical(Y_valid, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assert X_train_dict['left'].shape == X_train_dict['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assert len(X_train_dict['left']) == len(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#padding to max seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad_left_zeros(question_list,max_seq_length):\n",
    "    question_list = [0] * (max_seq_length - len(question_list)) + question_list\n",
    "    return question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len (pad_left_zeros([31586, 69984, 104295, 57112, 55384, 21628, 63296, 131479, 95639]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'] = X_train_df['question1'].apply(lambda x: pad_left_zeros(x,max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df['question2'] = X_train_df['question2'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_valid_df['question1'] = X_valid_df['question1'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_valid_df['question2'] = X_valid_df['question2'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_test_df['question1'] = X_test_df['question1'].apply(lambda x: pad_left_zeros(x,max_seq_length))\n",
    "X_test_df['question2'] = X_test_df['question2'].apply(lambda x: pad_left_zeros(x,max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split to dicts\n",
    "X_train_dict = {'left': X_train_df['question1'], 'right': X_train_df['question2']}\n",
    "X_valid_dict = {'left': X_valid_df['question1'], 'right': X_valid_df['question2']}\n",
    "X_test_dict = {'left': X_test_df['question1'], 'right': X_test_df['question2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "# shared_lstm = LSTM(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf;\n",
    "# import keras\n",
    "# print(keras.__version__)\n",
    "# print(tf.__version__)\n",
    "# python -c 'import keras; print(keras.__version__)'\n",
    "# python3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# left_output = shared_lstm(encoded_left)\n",
    "# right_output = shared_lstm(encoded_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# left_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can then concatenate the two vectors:\n",
    "# merged_vector = keras.layers.concatenate([left_output,right_output], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And add a logistic regression on top\n",
    "# predictions = Dense(2, activation='softmax')(merged_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dict['left'] = np.concatenate(X_train_dict['left']).reshape(X_train_dict['left'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dict['left'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_dict['right'] = np.concatenate(X_train_dict['right']).reshape(X_train_dict['right'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dict['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_dict['left'] = np.concatenate(X_valid_dict['left']).reshape(X_valid_dict['left'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_dict['right'] = np.concatenate(X_valid_dict['right']).reshape(X_valid_dict['right'].shape[0],max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dict['right'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "#Input None,max_seq_length,1\n",
    "\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embed_matrix),\n",
    "                            embed_length,\n",
    "                            weights=[embed_matrix],\n",
    "                            input_length=max_seq_length,\n",
    "                            trainable=False)\n",
    "\n",
    "#Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# encoded_left.shape\n",
    "\n",
    "# This layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "\n",
    "# left_output.shape\n",
    "\n",
    "# We can then concatenate the two vectors:\n",
    "merged_vector = keras.layers.concatenate([left_output,right_output], axis=-1)\n",
    "\n",
    "predictions = Dense(2, activation='softmax')(merged_vector)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[left_input, right_input], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "n_epoch = 1\n",
    "\n",
    "\n",
    "model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_model_input(input_questions,preprocess_text,words_to_index):\n",
    "\n",
    "    final_new_words_list = []\n",
    "\n",
    "    # i = 0\n",
    "    for words_list in input_questions:\n",
    "        new_words_list = []\n",
    "      \n",
    "        for word in preprocess_text(words_list):\n",
    "\n",
    "            if words_to_index.get(word):\n",
    "                new_words_list.append(words_to_index.get(word))\n",
    "             \n",
    "        final_new_words_list.append(np.array(pad_left_zeros(new_words_list,max_seq_length)))\n",
    "        \n",
    "         \n",
    "    return [final_new_words_list[0].reshape(1,max_seq_length), final_new_words_list[1].reshape(1,max_seq_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index):\n",
    "    y_prob = model.predict(preprocess_model_input(input_questions,preprocess_text,words_to_index),batch_size=1, verbose=0, steps=None)\n",
    "\n",
    "    print (\"The probabilities predicted by model for the question pair \\n {} for classes [0,1] are \\n {}\".format(input_questions,y_prob))\n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    print (\"The class that model predicted for the question pair \\n {} is {}\".format(input_questions,y_classes))\n",
    "    return y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"What is the capital of India?\", \"What is the capital of India?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"How can I be a good geologist?\", \"What should I do to be a great geologist?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"What is the best travel website in spain?\", \"What is the best travel website?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n_epoch = 4\n",
    "\n",
    "\n",
    "model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n_epoch = 6\n",
    "\n",
    "\n",
    "model.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"What is the capital of India?\", \"What is the capital of India?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"How can I be a good geologist?\", \"What should I do to be a great geologist?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"What is the best travel website in spain?\", \"What is the best travel website?\"]\n",
    "model_prediction(model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# # save the tokenizer and model\n",
    "# with open(\"keras_tokenizer.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(tokenizer, f)\n",
    "model.save(\"../quora_keras_model_v2_tokenizer.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('words_to_index_v2.pickle', 'rb') as handle:\n",
    "    words_to_index_1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('index_to_words_v2.pickle', 'rb') as handle:\n",
    "    index_to_words_1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_questions = [\"How do I read and find my YouTube comments?\", \"How can I see all my Youtube comments?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "predict_model = load_model(\"../quora_keras_model_v2_tokenizer.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_prediction(predict_model,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Increasing model layers to see if increase layers increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "#Input None,max_seq_length,1\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embed_matrix),\n",
    "                            embed_length,\n",
    "                            weights=[embed_matrix],\n",
    "                            input_length=max_seq_length,\n",
    "                            trainable=False)\n",
    "\n",
    "#Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# encoded_left.shape\n",
    "\n",
    "# This layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "\n",
    "# left_output.shape\n",
    "\n",
    "# We can then concatenate the two vectors:\n",
    "merged_vector = keras.layers.concatenate([left_output,right_output], axis=-1)\n",
    "\n",
    "merged_vector = Dense(64, activation='relu')(merged_vector)\n",
    "merged_vector = Dense(64, activation='relu')(merged_vector)\n",
    "merged_vector = Dense(64, activation='relu')(merged_vector)\n",
    "\n",
    "predictions = Dense(2, activation='softmax')(merged_vector)\n",
    "\n",
    "\n",
    "\n",
    "model_dense = Model(inputs=[left_input, right_input], outputs=predictions)\n",
    "\n",
    "model_dense.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "n_epoch = 1\n",
    "\n",
    "\n",
    "model_dense_hist = model_dense.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n_epoch = 4\n",
    "\n",
    "\n",
    "model_dense_hist = model_dense.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 5\n",
    "\n",
    "\n",
    "model_dense_hist = model_dense.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 1\n",
    "model_dense_hist = model_dense.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 1\n",
    "model_dense_hist = model_dense.fit([X_train_dict['left'], X_train_dict['right']], Y_train, batch_size=128, epochs=n_epoch,\n",
    "         validation_data=([X_valid_dict['left'], X_valid_dict['right']], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(model_dense_hist.history['acc'])\n",
    "plt.plot(model_dense_hist.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(model_dense_hist.history['loss'])\n",
    "plt.plot(model_dense_hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (model_dense_hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"How can I be a good geologist?\", \"What should I do to be a great geologist?\"]\n",
    "model_prediction(model_dense,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_questions = [\"What is the best travel website in spain?\", \"What is the best travel website?\"]\n",
    "model_prediction(model_dense,input_questions,preprocess_model_input,preprocess_text,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re.sub(r\"[^A-Za-z0-9,!.\\/'+-=]\", \" \", 'why am i mentally very lonely? how can i solve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re.sub(r\"\\'s\", \" \", 'what\\'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# words_list = []\n",
    "# # train_subset_df = train_df['question1'][0:10]\n",
    "# train_subset_df['question1'] = pd.DataFrame(data=train_df['question1'][0:10], columns=['question1'])\n",
    "# train_subset_df['question2'] = pd.DataFrame(data=train_df['question2'][0:10], columns=['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for sentence in train_subset_df['question1']:\n",
    "#     for word in sentence:\n",
    "#         words_list.append(word)\n",
    "# print (len(set(words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature based on how many words are common in question 1 and question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# u.termfrequency(['What is the step by step guide to invest in share market in india?'], ['What is the step by step guide to invest in share market?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def termfrequency(sentence1, sentence2):\n",
    "   \n",
    "    question_dict ={}\n",
    "    sentence1_words = sentence1   \n",
    "    sentence2_words = sentence2\n",
    "    searchtermfreq = []\n",
    "    i = 0\n",
    "    \n",
    "    for key in sentence1_words:\n",
    "#         print (key)\n",
    "        question_dict[key] = question_dict.get(key,0) + 1\n",
    "    \n",
    "    for key in set(sentence2_words):\n",
    "        value =  question_dict.get(key,0)\n",
    "        if value >= 1:\n",
    "            value = 1\n",
    "        searchtermfreq.append(value)\n",
    "        \n",
    "    \n",
    "#     print (question_dict)\n",
    "#     print (searchtermfreq)\n",
    "#     print (sum(searchtermfreq))\n",
    "    return sum(searchtermfreq)\n",
    "\n",
    "termfrequency(['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india?'], ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market?'])\n",
    "    \n",
    "X_train_df['common_term_freq'] = X_train_df.apply(lambda x: termfrequency(x['question1'],x['question2']), axis=1 )\n",
    "\n",
    "X_train_df.head(10)\n",
    "\n",
    "X_valid_df['common_term_freq'] = X_valid_df.apply(lambda x: termfrequency(x['question1'],x['question2']), axis=1 )\n",
    "\n",
    "X_valid_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Total words frequency\n",
    "\n",
    "def total_words_freq(sentence):\n",
    "    return len(sentence)\n",
    "\n",
    "total_words_freq(['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india?'])\n",
    "\n",
    "X_train_df['question1_words_freq'] = X_train_df['question1'].map(lambda x: total_words_freq(x))\n",
    "X_train_df['question2_words_freq'] = X_train_df['question2'].map(lambda x: total_words_freq(x))\n",
    "\n",
    "X_train_df.head(5)\n",
    "\n",
    "X_valid_df['question1_words_freq'] = X_valid_df['question1'].map(lambda x: total_words_freq(x))\n",
    "X_valid_df['question2_words_freq'] = X_valid_df['question2'].map(lambda x: total_words_freq(x))\n",
    "\n",
    "X_valid_df.head(5)\n",
    "X_train_model_input = X_train_df.drop(['question1','question2'],axis =1)\n",
    "X_valid_model_input = X_valid_df.drop(['question1','question2'],axis =1)\n",
    "X_train_model_input.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train a model# Train  \n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print (\"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "    \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf =  LogisticRegression()\n",
    "\n",
    "train_classifier(clf, X_train_model_input, y_train.values.ravel())\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def predict_labels(clf, X_train, y_train):\n",
    "    print (\"Predicting labels using {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nPrediction time (secs): {:.3f}\".format(end - start))\n",
    "    return log_loss(y_train, y_pred, eps=1e-15), confusion_matrix(y_train, y_pred)\n",
    "\n",
    "train_metrics = predict_labels(clf, X_train_model_input, y_train.values.ravel())\n",
    "\n",
    "print \n",
    "print (\"Log loss for training set: {}\".format(train_metrics[0]))\n",
    "\n",
    "print (\"Confusion matrix for training set: {}\".format(train_metrics[1]))\n",
    "\n",
    "# Predict on test data\n",
    "print (\"Log loss for validation set: {}\".format(predict_labels(clf, X_valid_model_input, y_valid.values.ravel())[0]))\n",
    "\n",
    "print (\"Confusion matrix for validation set: {}\".format(predict_labels(clf, X_valid_model_input, y_valid.values.ravel())[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_list = create_vocabulary([],X_train_df,'question1')\n",
    "print (\"Lenght of words in X_train_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_train_df,'question2')\n",
    "print (\"Lenght of words after adding X_train_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question1')\n",
    "print (\"Lenght of words after adding X_valid_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_valid_df,'question2')\n",
    "print (\"Lenght of words after adding X_valid_df question 2 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question1')\n",
    "print (\"Lenght of words after adding X_test_df question 1 {}\".format(len(words_list)))\n",
    "words_list = create_vocabulary(words_list,X_test_df,'question2')\n",
    "print (\"Lenght of words after adding X_test_df question 2 {}\".format(len(words_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(list_words):\n",
    "     list_words_processed = []\n",
    "     for text in list_words:\n",
    "         text = re.sub(r\"\\?\", '', text)\n",
    "         text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#          print (text)\n",
    "         list_words_processed.append(str(text))\n",
    "#          print (list_words_processed)\n",
    "     return list_words_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text(['India?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text(['how',\n",
    " 'do',\n",
    " 'the',\n",
    " 'holy',\n",
    " 'scriptures',\n",
    " 'of',\n",
    " 'hinduism',\n",
    " 'compare',\n",
    " 'and',\n",
    " 'contrast',\n",
    " 'to',\n",
    " 'those',\n",
    " 'of',\n",
    " 'taoism?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_df['question1'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text(X_train_df['question1'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_p_df = pd.DataFrame()\n",
    "X_valid_p_df = pd.DataFrame()\n",
    "X_test_p_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_p_df['question1'] = X_train_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_train_p_df['question2'] = X_train_df['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_p_df['question1'] = X_valid_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_valid_p_df['question2'] = X_valid_df['question2'].apply(lambda x:preprocess_text(x))\n",
    "X_test_p_df['question1'] = X_test_df['question1'].apply(lambda x:preprocess_text(x))\n",
    "X_test_p_df['question2'] = X_test_df['question2'].apply(lambda x:preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_p_df['question1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_words_list = create_vocabulary([],X_train_p_df,'question1')\n",
    "print (\"Lenght of words in X_train_df question 1 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_train_p_df,'question2')\n",
    "print (\"Lenght of words after adding X_train_df question 2 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_valid_p_df,'question1')\n",
    "print (\"Lenght of words after adding X_valid_df question 1 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_valid_p_df,'question2')\n",
    "print (\"Lenght of words after adding X_valid_df question 2 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_test_p_df,'question1')\n",
    "print (\"Lenght of words after adding X_test_df question 1 {}\".format(len(words_list)))\n",
    "proc_words_list = create_vocabulary(words_list,X_test_p_df,'question2')\n",
    "print (\"Lenght of words after adding X_test_df question 2 {}\".format(len(words_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_words_freq = collections.Counter(proc_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_words_freq_10000 = proc_words_freq.most_common(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_word_in_word2vec = []\n",
    "proc_word_notin_word2vec = []\n",
    "\n",
    "for word in proc_words_freq.most_common(10000):\n",
    "    if word[0] in model.vocab:\n",
    "        proc_word_in_word2vec.append(word[0])\n",
    "    else:\n",
    "        proc_word_notin_word2vec.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(proc_word_in_word2vec))\n",
    "print (len(proc_word_notin_word2vec))\n",
    "print (proc_word_notin_word2vec[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (proc_word_in_word2vec[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "quoravenv",
   "language": "python",
   "name": "quoravenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
